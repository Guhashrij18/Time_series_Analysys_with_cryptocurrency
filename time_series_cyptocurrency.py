# -*- coding: utf-8 -*-
"""Time series cyptocurrency.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12OWVAOoysUX3sWHmvIjVFhS0JgcNZbCe
"""

!pip install requests

import requests
import pandas as pd
import matplotlib.pyplot as plt
url = "https://api.coingecko.com/api/v3/coins/bitcoin/market_chart"
params = {
    "vs_currency": "usd",
    "days": "365",
    "interval": "daily"
}
response = requests.get(url, params=params)
data = response.json()
timestamps = [entry[0] for entry in data["prices"]]
prices = [entry[1] for entry in data["prices"]]
df = pd.DataFrame({"Date": pd.to_datetime(timestamps, unit="ms"), "Price": prices})
df.set_index("Date", inplace=True)
print(df.head())
df.to_csv("bitcoin_prices.csv")

plt.figure(figsize=(12, 6))
plt.plot(df.index, df["Price"], label="Bitcoin Price (USD)", color="blue")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.title("Bitcoin Price Trend (Last 1 Year)")

plt.figure(figsize=(12, 6))
plt.plot(df.index, df["Price"], label="Bitcoin Price (USD)", color="blue")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.title("Bitcoin Price Trend (Last 1 Year)")
plt.legend()
plt.grid()
plt.show()

!pip install statsmodels tensorflow keras prophet

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.arima.model import ARIMA
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from prophet import Prophet
from sklearn.preprocessing import MinMaxScaler
df = pd.read_csv("/content/bitcoin_prices.csv", parse_dates=['Date'], index_col='Date')
print(df.head())

#Train ARIMA Model
model_arima = ARIMA(df['Price'], order=(5,1,0))
model_arima_fit = model_arima.fit()
forecast_arima = model_arima_fit.forecast(steps=30)

plt.figure(figsize=(12, 6))
plt.plot(df.index, df["Price"], label="Actual Price")
plt.plot(pd.date_range(start=df.index[-1], periods=31, freq="D")[1:], forecast_arima, label="ARIMA Forecast", linestyle="dashed", color="red")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.title("Bitcoin Price Prediction using ARIMA")
plt.legend()
plt.show()

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(df["Price"].values.reshape(-1,1))
def create_dataset(data, time_step=60):
    X, Y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        Y.append(data[i + time_step, 0])
    return np.array(X), np.array(Y)

time_step = 60
X, Y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
Y_train, Y_test = Y[:train_size], Y[train_size:]

#Build and train LSTM Model
model_lstm = Sequential([
    LSTM(50, return_sequences=True, input_shape=(time_step, 1)),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(1)
])

model_lstm.compile(optimizer="adam", loss="mean_squared_error")
model_lstm.fit(X_train, Y_train, batch_size=1, epochs=10)

#forecast with LSTM predict last 30 days
X_input = scaled_data[-time_step:].reshape(1, time_step, 1)
lstm_predictions = []

for _ in range(30):
    pred = model_lstm.predict(X_input)
    lstm_predictions.append(pred[0,0])
    X_input = np.append(X_input[:,1:,:], pred.reshape(1,1,1), axis=1)

lstm_predictions = scaler.inverse_transform(np.array(lstm_predictions).reshape(-1,1))

plt.figure(figsize=(12, 6))
plt.plot(df.index, df["Price"], label="Actual Price")
plt.plot(pd.date_range(start=df.index[-1], periods=31, freq="D")[1:], lstm_predictions, label="LSTM Forecast", linestyle="dashed", color="green")
plt.xlabel("Date")
plt.ylabel("Price (USD)")
plt.title("Bitcoin Price Prediction using LSTM")
plt.legend()
plt.show()

#Forecasting with facebook prophet
#prepare data for prophet
df_prophet = df.reset_index()[['Date', 'Price']]
df_prophet.columns = ['ds', 'y']

#train prophet model
model_prophet = Prophet()
model_prophet.fit(df_prophet)
future = model_prophet.make_future_dataframe(periods=30)
forecast = model_prophet.predict(future)
model_prophet.plot(forecast)
plt.show()

#Evaluate Model Performance
from sklearn.metrics import mean_squared_error
import numpy as np

arima_rmse = np.sqrt(mean_squared_error(df['Price'][-30:], forecast_arima))
print(f"ARIMA RMSE: {arima_rmse}")

lstm_rmse = np.sqrt(mean_squared_error(df['Price'][-30:], lstm_predictions))
print(f"LSTM RMSE: {lstm_rmse}")

prophet_rmse = np.sqrt(mean_squared_error(df['Price'][-30:].values, forecast['yhat'][-30:].values))
print(f"Prophet RMSE: {prophet_rmse}")

#Tune the Models for Better Predictions
#ARIMA Hyperparameter Tuning (find the best p, d, q)
#LSTM Hyperparameter Tuning (adjust layers, neurons, epochs)
#Prophet Seasonal Adjustments
!pip install pmdarima
from pmdarima import auto_arima

auto_model = auto_arima(df['Price'], seasonal=False, stepwise=True, suppress_warnings=True)
print(auto_model.summary())

import time
import requests

# Set the number of iterations you want the loop to run for
max_iterations = 5  # For example, stop after 10 iterations

for i in range(max_iterations):
    response = requests.get("https://api.coingecko.com/api/v3/simple/price", params={"ids": "bitcoin", "vs_currencies": "usd"})

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        btc_price = response.json()["bitcoin"]["usd"]
        print(f"Live Bitcoin Price: ${btc_price}")  # This line prints the price
    else:
        print(f"Error fetching price: Status code {response.status_code}") # This line prints an error

    time.sleep(10)  # Wait 10 seconds before fetching again to avoid rate limiting

print("Loop finished.")

#Deploy as a webapp in streamlit
!pip install streamlit
import streamlit as st

st.title("Bitcoin Price Forecasting")

# Show actual price chart
st.line_chart(df['Price'])

# Show ARIMA forecast
st.line_chart(forecast_arima)

# Show LSTM forecast
st.line_chart(lstm_predictions)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt

df = pd.read_csv("/content/bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")

st.title("Bitcoin Price Forecasting")

# Show Historical Data
st.subheader("Bitcoin Price Data")
st.write(df.tail())

# Plot Actual Prices
st.subheader("Bitcoin Price Trend")
st.line_chart(df["Price"])

# ARIMA Forecast Plot
st.subheader("ARIMA Forecast")
# Adjust the periods in pd.date_range to 31 and keep [1:] to get 30 periods to match forecast_arima
st.line_chart(pd.concat([df["Price"].iloc[-30:], pd.Series(forecast_arima.values, index=pd.date_range(start=df.index[-1], periods=31, freq="D")[1:])]))

st.subheader("LSTM Forecast")
st.line_chart(pd.concat([df["Price"].iloc[-30:], pd.Series(lstm_predictions.flatten(), index=pd.date_range(start=df.index[-1], periods=31, freq="D")[1:])]))
# Change periods to 31 to generate 30 dates after excluding the first with [1:]

!pip install pyngrok
!pip install streamlit pyngrok

!ngrok authtoken 2uBKFFrECRNBHqLtXYKuRepg7tk_6drokNi5jKGReR2aoAdzZ

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# # Load Bitcoin Price Data
# df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")
# 
# # Streamlit UI
# st.title("ğŸ“ˆ Bitcoin Price Forecasting")
# # Show Historical Data
# st.subheader("Bitcoin Price Data")
# st.write(df.tail())
# 
# # Plot Actual Prices
# st.subheader("Bitcoin Price Trend")
# st.line_chart(df["Price"])
# 
# st.write("Built with Streamlit")

import threading
import subprocess
from pyngrok import ngrok

# Kill any previous Streamlit or ngrok processes
!killall ngrok  # Added this line to kill all ngrok instances
!kill -9 $(pgrep streamlit)

# Start Streamlit in the background
def run_streamlit():
    subprocess.run(["streamlit", "run", "app.py"])

thread = threading.Thread(target=run_streamlit)
thread.start()

# Start ngrok
public_url = ngrok.connect(addr="8501")
print(f"Streamlit App is Running at: {public_url}")

# (Optional) Stop processes when done
!kill -9 $(pgrep streamlit)
!kill -9 $(pgrep ngrok)

!ls

from pyngrok import ngrok

# Start ngrok tunnel with the correct configuration (without "options")
public_url = ngrok.connect(addr="8501")
print(f"Streamlit App is Running at: {public_url}")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# 
# st.title("Bitcoin Price Forecasting")
# st.write("Hello! This is a simple Streamlit app.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# 
# # Load Bitcoin Price Data
# df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")
# 
# # Streamlit UI
# st.title("Bitcoin Price Forecasting")
# st.write("Welcome! This dashboard shows Bitcoin price trends and predictions.")
# 
# # Show Data Preview
# st.subheader("Bitcoin Price Data")
# st.write(df.tail())
# 
# # Plot Bitcoin Price Trend
# st.subheader("Bitcoin Price Trend")
# st.line_chart(df["Price"])
# 
# st.write("Built with Streamlit")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# 
# # Load Bitcoin Price Data
# df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")

from statsmodels.tsa.arima.model import ARIMA
import pandas as pd

# Load Bitcoin data
df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")

# Train ARIMA model
model_arima = ARIMA(df['Price'], order=(5,1,0))
model_arima_fit = model_arima.fit()

# Forecast the next 30 days
forecast_arima = model_arima_fit.forecast(steps=30)

# Save ARIMA Predictions
df_arima_forecast = pd.DataFrame({"Date": pd.date_range(start=df.index[-1], periods=31, freq="D")[1:], "Forecast": forecast_arima})
df_arima_forecast.to_csv("arima_forecast.csv", index=False)
print("ARIMA Forecast Saved!")

import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# Load Bitcoin data
df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")

# Scale Data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(df["Price"].values.reshape(-1,1))

# Prepare Data for LSTM
time_step = 60
X, Y = [], []
for i in range(len(scaled_data) - time_step - 1):
    X.append(scaled_data[i:(i + time_step), 0])
    Y.append(scaled_data[i + time_step, 0])

X = np.array(X).reshape(-1, time_step, 1)
Y = np.array(Y)

# Train LSTM Model
model_lstm = Sequential([
    LSTM(50, return_sequences=True, input_shape=(time_step, 1)),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(1)
])

model_lstm.compile(optimizer="adam", loss="mean_squared_error")
model_lstm.fit(X, Y, batch_size=1, epochs=10)

# Predict Next 30 Days
X_input = scaled_data[-time_step:].reshape(1, time_step, 1)
lstm_predictions = []
for _ in range(30):
    pred = model_lstm.predict(X_input)
    lstm_predictions.append(pred[0,0])
    X_input = np.append(X_input[:,1:,:], pred.reshape(1,1,1), axis=1)

# Convert Back to Original Scale
lstm_predictions = scaler.inverse_transform(np.array(lstm_predictions).reshape(-1,1))

# Save LSTM Predictions
df_lstm_forecast = pd.DataFrame({"Date": pd.date_range(start=df.index[-1], periods=31, freq="D")[1:], "Forecast": lstm_predictions.flatten()})
df_lstm_forecast.to_csv("lstm_forecast.csv", index=False)
print("LSTM Forecast Saved!")

from prophet import Prophet

# Load Bitcoin data
df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")

# Prepare Data for Prophet
df_prophet = df.reset_index()[['Date', 'Price']]
df_prophet.columns = ['ds', 'y']

# Train Prophet Model
model_prophet = Prophet()
model_prophet.fit(df_prophet)

# Predict Future
future = model_prophet.make_future_dataframe(periods=30)
forecast = model_prophet.predict(future)

# Save Prophet Predictions
df_prophet_forecast = forecast[['ds', 'yhat']].rename(columns={'ds': 'Date', 'yhat': 'Forecast'})
df_prophet_forecast.to_csv("prophet_forecast.csv", index=False)
print("Prophet Forecast Saved!")

!ls

# Load Forecasts (Ensure these CSV files exist before running the app)
df_arima = pd.read_csv("arima_forecast.csv", parse_dates=["Date"], index_col="Date")
df_lstm = pd.read_csv("lstm_forecast.csv", parse_dates=["Date"], index_col="Date")
df_prophet = pd.read_csv("prophet_forecast.csv", parse_dates=["Date"], index_col="Date")
st.title("Bitcoin Price Forecasting Dashboard")
st.write("Welcome! This dashboard visualizes Bitcoin price trends and forecasts.")

st.subheader("Bitcoin Price Data")
st.write(df.tail())

st.subheader("Bitcoin Price Trend")
st.line_chart(df["Price"])

# Forecasting Section
st.subheader("Forecasted Bitcoin Prices")

st.write("### ARIMA Model Prediction")
fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(df.index, df["Price"], label="Actual Price", color="blue")
ax.plot(df_arima.index, df_arima["Forecast"], label="ARIMA Forecast", linestyle="dashed", color="red")
ax.legend()
st.pyplot(fig)

st.write("### LSTM Model Prediction")
fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(df.index, df["Price"], label="Actual Price", color="blue")
ax.plot(df_lstm.index, df_lstm["Forecast"], label="LSTM Forecast", linestyle="dashed", color="green")
ax.legend()
st.pyplot(fig)

st.write("### Prophet Model Prediction")
fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(df.index, df["Price"], label="Actual Price", color="blue")
ax.plot(df_prophet.index, df_prophet["Forecast"], label="Prophet Forecast", linestyle="dashed", color="purple")
ax.legend()
st.pyplot(fig)

st.write("Built with Streamlit")

from statsmodels.tsa.arima.model import ARIMA

# Train ARIMA model
model_arima = ARIMA(df['Price'], order=(5,1,0))
model_arima_fit = model_arima.fit()

# Forecast the next 30 days
forecast_arima = model_arima_fit.forecast(steps=30)

# Create DataFrame and Save
df_arima_forecast = pd.DataFrame({"Date": pd.date_range(start=df.index[-1], periods=31, freq="D")[1:], "Forecast": forecast_arima})
df_arima_forecast.to_csv("arima_forecast.csv", index=False)

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# Scale Data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(df["Price"].values.reshape(-1,1))

# Prepare Data for LSTM
time_step = 60
X, Y = [], []
for i in range(len(scaled_data) - time_step - 1):
    X.append(scaled_data[i:(i + time_step), 0])
    Y.append(scaled_data[i + time_step, 0])

X = np.array(X).reshape(-1, time_step, 1)
Y = np.array(Y)

# Train LSTM Model
model_lstm = Sequential([
    LSTM(50, return_sequences=True, input_shape=(time_step, 1)),
    LSTM(50, return_sequences=False),
    Dense(25),
    Dense(1)
])

model_lstm.compile(optimizer="adam", loss="mean_squared_error")
model_lstm.fit(X, Y, batch_size=1, epochs=10)

# Predict Next 30 Days
X_input = scaled_data[-time_step:].reshape(1, time_step, 1)
lstm_predictions = []
for _ in range(30):
    pred = model_lstm.predict(X_input)
    lstm_predictions.append(pred[0,0])
    X_input = np.append(X_input[:,1:,:], pred.reshape(1,1,1), axis=1)

# Convert Back to Original Scale
lstm_predictions = scaler.inverse_transform(np.array(lstm_predictions).reshape(-1,1))

# Save Predictions
df_lstm_forecast = pd.DataFrame({"Date": pd.date_range(start=df.index[-1], periods=31, freq="D")[1:], "Forecast": lstm_predictions.flatten()})
df_lstm_forecast.to_csv("lstm_forecast.csv", index=False)

from prophet import Prophet

# Prepare Data for Prophet
df_prophet = df.reset_index()[['Date', 'Price']]
df_prophet.columns = ['ds', 'y']

# Train Prophet Model
model_prophet = Prophet()
model_prophet.fit(df_prophet)

# Predict Future
future = model_prophet.make_future_dataframe(periods=30)
forecast = model_prophet.predict(future)

# Save Predictions
df_prophet_forecast = forecast[['ds', 'yhat']].rename(columns={'ds': 'Date', 'yhat': 'Forecast'})
df_prophet_forecast.to_csv("prophet_forecast.csv", index=False)

!ls -l

import pandas as pd

# Check Bitcoin prices
df_bitcoin = pd.read_csv("bitcoin_prices.csv")
print("Bitcoin Prices Data:")
print(df_bitcoin.head())

# Check ARIMA forecast
df_arima = pd.read_csv("arima_forecast.csv")
print("\nARIMA Forecast Data:")
print(df_arima.head())

# Check LSTM forecast
df_lstm = pd.read_csv("lstm_forecast.csv")
print("\nLSTM Forecast Data:")
print(df_lstm.head())

# Check Prophet forecast
df_prophet = pd.read_csv("prophet_forecast.csv")
print("\nProphet Forecast Data:")
print(df_prophet.head())

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# 
# st.title("Streamlit Test")
# st.write("If you see this message, Streamlit is working correctly!")
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# 
# # Load Data (Handle Missing Files)
# try:
#     df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")
#     df_arima = pd.read_csv("arima_forecast.csv", parse_dates=["Date"], index_col="Date")
#     df_lstm = pd.read_csv("lstm_forecast.csv", parse_dates=["Date"], index_col="Date")
#     df_prophet = pd.read_csv("prophet_forecast.csv", parse_dates=["Date"], index_col="Date")
# except Exception as e:
#     st.error(f"Error loading files: {e}")
#     st.stop()
# 
# # Streamlit UI
# st.title("Bitcoin Price Forecasting Dashboard")
# st.write("Welcome! This dashboard visualizes Bitcoin price trends and forecasts.")
# 
# # Show Data Preview
# st.subheader("Bitcoin Price Data")
# st.write(df.tail())
# 
# # Plot Bitcoin Price Trend
# st.subheader("Bitcoin Price Trend")
# st.line_chart(df["Price"])
# 
# # Forecasting Section
# st.subheader("Forecasted Bitcoin Prices")
# 
# # ARIMA Forecast Plot
# st.write("### ARIMA Model Prediction")
# fig, ax = plt.subplots(figsize=(10, 5))
# ax.plot(df.index, df["Price"], label="Actual Price", color="blue")
# ax.plot(df_arima.index, df_arima["Forecast"], label="ARIMA Forecast", linestyle="dashed", color="red")
# ax.legend()
# st.pyplot(fig)
# 
# # LSTM Forecast Plot
# st.write("### LSTM Model Prediction")
# fig, ax = plt.subplots(figsize=(10, 5))
# ax.plot(df.index, df["Price"], label="Actual Price", color="blue")
# ax.plot(df_lstm.index, df_lstm["Forecast"], label="LSTM Forecast", linestyle="dashed", color="green")
# ax.legend()
# st.pyplot(fig)
# 
# # Prophet Forecast Plot
# st.write("### Prophet Model Prediction")
# fig, ax = plt.subplots(figsize=(10, 5))
# ax.plot(df.index, df["Price"], label="Actual Price", color="blue")
# ax.plot(df_prophet.index, df_prophet["Forecast"], label="Prophet Forecast", linestyle="dashed", color="purple")
# ax.legend()
# st.pyplot(fig)
#

import threading
import subprocess
from pyngrok import ngrok

# Kill old processes
!kill -9 $(pgrep streamlit)
!kill -9 $(pgrep ngrok)

# Start Streamlit in the background
def run_streamlit():
    subprocess.run(["streamlit", "run", "app.py", "--server.port", "8501", "--browser.serverAddress", "0.0.0.0"])

thread = threading.Thread(target=run_streamlit)
thread.start()

# Start ngrok
public_url = ngrok.connect(addr="8501")
print(f"Streamlit App is Running at: {public_url}")

!pip install pmdarima
from pmdarima import auto_arima

# Automatically select best (p, d, q) values
auto_model = auto_arima(df["Price"], seasonal=False, stepwise=True, suppress_warnings=True)
print(auto_model.summary())

from tensorflow.keras.layers import Bidirectional, Dropout

model_lstm = Sequential([
    Bidirectional(LSTM(100, return_sequences=True, input_shape=(time_step, 1))),
    Dropout(0.2),
    Bidirectional(LSTM(100, return_sequences=False)),
    Dense(50, activation="relu"),
    Dense(1)
])

model_lstm.compile(optimizer="adam", loss="mean_squared_error")
model_lstm.fit(X, Y, batch_size=16, epochs=20)

df_prophet = df_prophet.rename(columns={"Date": "ds", "Forecast": "y"})

model_prophet = Prophet()
model_prophet.add_seasonality(name='monthly', period=30, fourier_order=5)
model_prophet.fit(df_prophet)

coins = ["bitcoin", "ethereum", "binancecoin"]

for coin in coins:
    url = f"https://api.coingecko.com/api/v3/coins/{coin}/market_chart"
    params = {"vs_currency": "usd", "days": "365", "interval": "daily"}
    response = requests.get(url, params=params)

    data = response.json()
    df = pd.DataFrame({"Date": pd.to_datetime([entry[0] for entry in data["prices"]], unit="ms"),
                       "Price": [entry[1] for entry in data["prices"]]})

    df.to_csv(f"{coin}_prices.csv", index=False)

import time
import requests

# Set the number of iterations you want the loop to run for
max_iterations = 5  # For example, stop after 5 iterations

for i in range(max_iterations):
    response = requests.get("https://api.coingecko.com/api/v3/simple/price", params={"ids": "bitcoin", "vs_currencies": "usd"})

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        btc_price = response.json()["bitcoin"]["usd"]
        print(f"Live Bitcoin Price: ${btc_price}")  # This line prints the price
    else:
        print(f"Error fetching price: Status code {response.status_code}") # This line prints an error message with the code
        # You can handle this error by retrying after a delay or exit the loop if needed
        break # exit the loop immediately to prevent further api calls

    # Wait 10 seconds to avoid overloading the API
    time.sleep(10)

print("Loop finished.")

import time
import requests
import pandas as pd

max_iterations = 5  # Stop after 5 iterations
live_prices = []  # List to store price data

for i in range(max_iterations):
    response = requests.get("https://api.coingecko.com/api/v3/simple/price", params={"ids": "bitcoin", "vs_currencies": "usd"})

    if response.status_code == 200:
        btc_price = response.json()["bitcoin"]["usd"]
        timestamp = pd.Timestamp.now()  # Get current time
        print(f"{timestamp} - Live Bitcoin Price: ${btc_price}")

        # Store data in a list
        live_prices.append([timestamp, btc_price])

    else:
        print(f"Error fetching price: Status code {response.status_code}")
        break  # Exit loop if API fails

    time.sleep(10)  # Wait before fetching again

# Save to CSV
df = pd.DataFrame(live_prices, columns=["Timestamp", "Price"])
df.to_csv("live_bitcoin_prices.csv", index=False)

print("Live Bitcoin price data saved to CSV!")

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA

# Load historical data & new live prices
df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")
df_live = pd.read_csv("live_bitcoin_prices.csv", parse_dates=["Timestamp"], index_col="Timestamp")

# Combine datasets
df_updated = pd.concat([df, df_live])
df_updated = df_updated.sort_index()  # Ensure chronological order

# Fit ARIMA Model
model_arima = ARIMA(df_updated["Price"], order=(5,1,0))
model_arima_fit = model_arima.fit()

# Forecast next 30 days
forecast_arima = model_arima_fit.forecast(steps=30)

# Save new forecast
df_forecast = pd.DataFrame({"Date": pd.date_range(start=df_updated.index[-1], periods=31, freq="D")[1:], "Forecast": forecast_arima})
df_forecast.to_csv("updated_arima_forecast.csv", index=False)

print("âœ… ARIMA Forecast Updated with Real-Time Data!")

import streamlit as st
import pandas as pd
import os  # Import os to check if file exists

# Check if file exists
if os.path.exists("live_bitcoin_prices.csv"):
    # Load latest prices
    df_live = pd.read_csv("live_bitcoin_prices.csv")

    # Check if the DataFrame is empty
    if df_live.empty:
        st.error("Live Bitcoin price data is empty. Please run the script that generates this data and try again.")
        st.stop()  # Prevent the rest of the app from running
    else:
        # Show latest price if the DataFrame is not empty
        st.metric(label="Current Bitcoin Price (USD)", value=df_live["Price"].iloc[-1])

        # Show live price trend
        st.line_chart(df_live.set_index("Timestamp")["Price"])

        st.write("Live Bitcoin price updates every 10 seconds!")

else:
    # Handle case where the file is not found
    st.error("Live Bitcoin price data is not available. Please run the script that generates this data and try again.")
    st.stop() # Prevent the rest of the app from running

# Streamlit UI
st.title("Real-Time Bitcoin Price Tracking")
st.write("Live data from CoinGecko API")

df.to_csv("bitcoin_prices_for_powerbi.csv", index=True)

import pandas as pd
import matplotlib.pyplot as plt

# Load Bitcoin Price Data
df = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")

# Calculate 7-day rolling volatility
df["Volatility"] = df["Price"].pct_change().rolling(7).std()

# Plot Volatility
plt.figure(figsize=(12, 5))
plt.plot(df.index, df["Volatility"], color="red", label="7-Day Volatility")
plt.xlabel("Date")
plt.ylabel("Volatility")
plt.title("Bitcoin Volatility Over Time")
plt.legend()
plt.show()

!pip install tweepy nltk

import tweepy

# Add your Twitter API keys here
API_KEY = "LcQjbbPFxbztSDR1gMG7Y5B9J"
API_SECRET = "Ji4xgK0yR31a2ai8xDEsW6ysAKGGV8BRHyMk4MKacTGBCvbFRT"
ACCESS_TOKEN = "1899864433561911296-g1IPsPY2DuBjVlKsAL5uGuchTpdCaB"
ACCESS_SECRET = "NjWVXnETSlZzP1l645B2xh1jO1ObxKfGYNhJ8k5oIf2jj"

# Authenticate with Twitter API
auth = tweepy.OAuthHandler(API_KEY, API_SECRET)
auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)
api = tweepy.API(auth, wait_on_rate_limit=True)  # Prevents API limit errors

# Test Authentication
try:
    api.verify_credentials()
    print("Twitter API Authentication Successful!")
except Exception as e:
    print(f"Error: {e}")

import tweepy
import time

# Add your Twitter API credentials
API_KEY = "LcQjbbPFxbztSDR1gMG7Y5B9J"
API_SECRET = "Ji4xgK0yR31a2ai8xDEsW6ysAKGGV8BRHyMk4MKacTGBCvbFRT"
ACCESS_TOKEN = "1899864433561911296-g1IPsPY2DuBjVlKsAL5uGuchTpdCaB"
ACCESS_SECRET = "NjWVXnETSlZzP1l645B2xh1jO1ObxKfGYNhJ8k5oIf2jj"
BEARER_TOKEN = "AAAAAAAAAAAAAAAAAAAAAGeTzwEAAAAAbLh4QAbyiGpRbitYKHDThFe9VwU%3DfiWAJHJQUKuKz1vPSpn6xhZJoipgFc87ckL2IWWeQ3uGwIwYa0"  # Required for API v2

# Authenticate using Tweepy v2
client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=True) # Added wait_on_rate_limit=True

# Search for recent Bitcoin-related tweets
query = "Bitcoin OR BTC OR Cryptocurrency -is:retweet lang:en"
tweet_count = 10  # Number of tweets to fetch

# Fetch tweets with rate limiting handling
tweets = client.search_recent_tweets(query=query, max_results=tweet_count)

# Display some tweets
for tweet in tweets.data[:5]:  # Show first 5 tweets
    print(f"Tweet: {tweet.text}\n")
    time.sleep(5)  # Add a delay of 5 seconds between displaying tweets

import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

# Download Sentiment Analysis Lexicon (if not already installed)
nltk.download("vader_lexicon")
sia = SentimentIntensityAnalyzer()

# Ensure tweets contain data
if tweets.data:
    # Extract text from each tweet and analyze sentiment
    sentiments = []
    for tweet in tweets.data:  # Use `.data` to access tweet text
        sentiment_score = sia.polarity_scores(tweet.text)["compound"]
        sentiments.append(sentiment_score)

    # Calculate Average Sentiment Score
    avg_sentiment = sum(sentiments) / len(sentiments)
    print(f"Average Sentiment Score: {avg_sentiment}")
else:
    print("No tweets found. Try a different search query.")

import pandas as pd

# Ensure tweets contain data
if tweets.data:
    # Extract text and sentiment scores
    tweet_texts = [tweet.text for tweet in tweets.data]  # Use `.data` to get tweet text
    df_sentiment = pd.DataFrame({
        "Tweet": tweet_texts,
        "Sentiment Score": sentiments
    })

    # Save to CSV
    df_sentiment.to_csv("crypto_sentiment.csv", index=False)
    print("Crypto Sentiment Data Saved to CSV!")
else:
    print("No tweets found. Try a different search query.")

import streamlit as st
import pandas as pd

# Load Sentiment Data
df_sentiment = pd.read_csv("crypto_sentiment.csv")

# Streamlit UI
st.title("Crypto Market Sentiment Analysis")
st.write("Real-time sentiment analysis of Bitcoin-related tweets.")

# Show latest sentiment scores
st.subheader("Sentiment Score Distribution")
st.bar_chart(df_sentiment["Sentiment Score"])

# Display sample tweets
st.subheader("Latest Tweets and Sentiments")
st.write(df_sentiment.head())

st.write("Stay Updated with Live Crypto Market Sentiment!")

import logging
import os
import warnings

# Suppress Streamlit warnings
warnings.filterwarnings("ignore")
os.environ["STREAMLIT_SUPPRESS_ERRORS"] = "1"

# Suppress logging messages
logging.getLogger("streamlit").setLevel(logging.ERROR)
logging.getLogger("py.warnings").setLevel(logging.ERROR)

import pandas as pd
import streamlit as st

# Load Sentiment Data
df_sentiment = pd.read_csv("crypto_sentiment.csv")

# Show Sentiment Data in the Dashboard
st.title("Crypto Market Sentiment Analysis")
st.write("Sentiment analysis of Bitcoin-related tweets.")

st.subheader("Sentiment Data Preview")
st.write(df_sentiment.head())

import matplotlib.pyplot as plt

# Calculate Sentiment Distribution
positive_tweets = len(df_sentiment[df_sentiment["Sentiment Score"] > 0])
neutral_tweets = len(df_sentiment[df_sentiment["Sentiment Score"] == 0])
negative_tweets = len(df_sentiment[df_sentiment["Sentiment Score"] < 0])

# Display Sentiment Distribution in a Bar Chart
st.subheader("ğŸ“Š Sentiment Distribution")

fig, ax = plt.subplots()
ax.bar(["Positive", "Neutral", "Negative"], [positive_tweets, neutral_tweets, negative_tweets], color=["green", "gray", "red"])
ax.set_ylabel("Number of Tweets")
ax.set_title("Sentiment Analysis of Bitcoin Tweets")
st.pyplot(fig)

# Dropdown to Filter Tweets
sentiment_filter = st.selectbox("ğŸ” Select Sentiment to View Tweets", ["All", "Positive", "Neutral", "Negative"])

# Filter Data
if sentiment_filter == "Positive":
    filtered_df = df_sentiment[df_sentiment["Sentiment Score"] > 0]
elif sentiment_filter == "Negative":
    filtered_df = df_sentiment[df_sentiment["Sentiment Score"] < 0]
elif sentiment_filter == "Neutral":
    filtered_df = df_sentiment[df_sentiment["Sentiment Score"] == 0]
else:
    filtered_df = df_sentiment

# Display Filtered Tweets
st.subheader(f"ğŸ“¢ {sentiment_filter} Tweets")
st.write(filtered_df[["Tweet", "Sentiment Score"]])

import threading
import subprocess
from pyngrok import ngrok

# Kill old processes
!kill -9 $(pgrep streamlit)
!kill -9 $(pgrep ngrok)

# Start Streamlit
def run_streamlit():
    subprocess.run(["streamlit", "run", "app.py", "--server.port", "8501", "--browser.serverAddress", "0.0.0.0"])

thread = threading.Thread(target=run_streamlit)
thread.start()

# Start ngrok
public_url = ngrok.connect(addr="8501")
print(f"Streamlit App is Running at: {public_url}")

import pandas as pd
df = pd.read_csv("crypto_sentiment.csv")
print(df.head())

import pandas as pd

# Check if sentiment data exists
try:
    df_sentiment = pd.read_csv("crypto_sentiment.csv")
    print("Sentiment Data Found!")
    print(df_sentiment.head())  # Show first 5 rows
except FileNotFoundError:
    print("ERROR: Sentiment data file not found! Run sentiment analysis again.")

!pip install --upgrade streamlit

!ls

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# st.title("Streamlit Dashboard")
# st.write("This is the starting point of your dashboard.")

!cat app.py

import os

files = ["bitcoin_prices.csv", "arima_forecast.csv", "lstm_forecast.csv", "prophet_forecast.csv", "crypto_sentiment.csv"]

for file in files:
    if os.path.exists(file):
        print(f"{file} exists!")
    else:
        print(f"ERROR: {file} is missing! Please generate it again.")

import pandas as pd

# Check if bitcoin_prices.csv exists
try:
    df = pd.read_csv("bitcoin_prices.csv")
    print("Bitcoin Price Data Found!")
    print(df.head())  # Display first few rows
except FileNotFoundError:
    print("ERROR: bitcoin_prices.csv not found! Generate it again.")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# 
# # ---- Load Data ----
# try:
#     # Load Bitcoin Price Data
#     df_prices = pd.read_csv("bitcoin_prices.csv", parse_dates=["Date"], index_col="Date")
# 
#     # Load Forecasting Data
#     df_arima = pd.read_csv("arima_forecast.csv", parse_dates=["Date"], index_col="Date")
#     df_lstm = pd.read_csv("lstm_forecast.csv", parse_dates=["Date"], index_col="Date")
#     df_prophet = pd.read_csv("prophet_forecast.csv", parse_dates=["Date"], index_col="Date")
# 
#     # Load Sentiment Data
#     df_sentiment = pd.read_csv("crypto_sentiment.csv")
# 
#     # ---- Streamlit UI ----
#     st.title("ğŸ“ˆ Cryptocurrency Price Forecasting & Sentiment Analysis")
#     st.write("Analyze Bitcoin trends using ARIMA, LSTM, Prophet, and sentiment analysis from Twitter.")
# 
#     # ---- Bitcoin Price Data ----
#     st.subheader("Bitcoin Price Data")
#     st.write("Here is the raw Bitcoin price data used for analysis:")
#     st.dataframe(df_prices.tail())  # Show last few rows of price data
# 
#     # ---- Bitcoin Price Trend ----
#     st.subheader("Bitcoin Price Trend")
#     st.line_chart(df_prices["Price"])
# 
#     # ---- ARIMA Forecast ----
#     st.subheader("ARIMA Model Prediction")
#     fig, ax = plt.subplots(figsize=(10, 5))
#     ax.plot(df_prices.index, df_prices["Price"], label="Actual Price", color="blue")
#     ax.plot(df_arima.index, df_arima["Forecast"], label="ARIMA Forecast", linestyle="dashed", color="red")
#     ax.legend()
#     st.pyplot(fig)
# 
#     # ---- LSTM Forecast ----
#     st.subheader("LSTM Model Prediction")
#     fig, ax = plt.subplots(figsize=(10, 5))
#     ax.plot(df_prices.index, df_prices["Price"], label="Actual Price", color="blue")
#     ax.plot(df_lstm.index, df_lstm["Forecast"], label="LSTM Forecast", linestyle="dashed", color="green")
#     ax.legend()
#     st.pyplot(fig)
# 
#     # ---- Prophet Forecast ----
#     st.subheader("Prophet Model Prediction")
#     fig, ax = plt.subplots(figsize=(10, 5))
#     ax.plot(df_prices.index, df_prices["Price"], label="Actual Price", color="blue")
#     ax.plot(df_prophet.index, df_prophet["Forecast"], label="Prophet Forecast", linestyle="dashed", color="purple")
#     ax.legend()
#     st.pyplot(fig)
# 
#     # ---- Sentiment Analysis ----
#     st.subheader("Crypto Market Sentiment Analysis")
#     st.write("Sentiment analysis of Bitcoin-related tweets.")
# 
#     # Show Sentiment Data
#     st.subheader("Sentiment Data Preview")
#     st.write(df_sentiment.head())  # Show first few tweets & scores
# 
#     # Calculate Sentiment Distribution
#     positive_tweets = len(df_sentiment[df_sentiment["Sentiment Score"] > 0])
#     neutral_tweets = len(df_sentiment[df_sentiment["Sentiment Score"] == 0])
#     negative_tweets = len(df_sentiment[df_sentiment["Sentiment Score"] < 0])
# 
#     # Show Sentiment Distribution Chart
#     st.subheader("Sentiment Distribution")
#     fig, ax = plt.subplots()
#     ax.bar(["Positive", "Neutral", "Negative"], [positive_tweets, neutral_tweets, negative_tweets], color=["green", "gray", "red"])
#     ax.set_ylabel("Number of Tweets")
#     ax.set_title("Sentiment Analysis of Bitcoin Tweets")
#     st.pyplot(fig)
# 
#     # Show Overall Market Sentiment
#     avg_sentiment = df_sentiment["Sentiment Score"].mean()
#     st.subheader("Overall Crypto Market Sentiment")
#     if avg_sentiment > 0:
#         st.write(f"ğŸŸ¢ **Positive Market Sentiment** (Score: {avg_sentiment:.2f})")
#     elif avg_sentiment < 0:
#         st.write(f"ğŸ”´ **Negative Market Sentiment** (Score: {avg_sentiment:.2f})")
#     else:
#         st.write(f"âšª **Neutral Market Sentiment** (Score: {avg_sentiment:.2f})")
# 
#     # Dropdown to Filter Tweets by Sentiment
#     sentiment_filter = st.selectbox("ğŸ” Select Sentiment to View Tweets", ["All", "Positive", "Neutral", "Negative"])
#     if sentiment_filter == "Positive":
#         filtered_df = df_sentiment[df_sentiment["Sentiment Score"] > 0]
#     elif sentiment_filter == "Negative":
#         filtered_df = df_sentiment[df_sentiment["Sentiment Score"] < 0]
#     elif sentiment_filter == "Neutral":
#         filtered_df = df_sentiment[df_sentiment["Sentiment Score"] == 0]
#     else:
#         filtered_df = df_sentiment
# 
#     # Display Filtered Tweets
#     st.subheader(f"{sentiment_filter} Tweets")
#     st.write(filtered_df[["Tweet", "Sentiment Score"]])
# 
# except FileNotFoundError as e:
#     st.error(f"Error loading data: {e}")
#

import threading
import subprocess
from pyngrok import ngrok

# Kill old Streamlit and ngrok processes (if any)
!kill -9 $(pgrep streamlit)
!kill -9 $(pgrep ngrok)

# Start Streamlit in a separate thread
def run_streamlit():
    subprocess.run(["streamlit", "run", "app.py", "--server.port", "8501", "--browser.serverAddress", "0.0.0.0"])

thread = threading.Thread(target=run_streamlit)
thread.start()

# Start ngrok to expose the Streamlit app
public_url = ngrok.connect(addr="8501")
print(f"Streamlit App is Running at: {public_url}")

import pandas as pd

df_prophet = pd.read_csv("prophet_forecast.csv")
print(df_prophet.head())  # Show first few rows
print(df_prophet.columns)  # Show column names

import pandas as pd

# Load the saved forecast
df_forecast = pd.read_csv("prophet_forecast.csv")

# Display column names and first few rows
print(df_forecast.columns)  # Check column names
print(df_forecast.head())   # Preview the first few rows

from prophet import Prophet
import pandas as pd

# Load your data
df = pd.read_csv("bitcoin_prices.csv")

# Rename columns for Prophet
df.rename(columns={"Date": "ds", "Price": "y"}, inplace=True)

# Initialize and fit the model
model = Prophet()
model.fit(df)  # âœ… Make sure to fit the model first

# Create future dataframe for prediction
future = model.make_future_dataframe(periods=100)  # Adjust period as needed

# Predict
forecast = model.predict(future)

# Rename and select required columns
forecast.rename(columns={"ds": "Date", "yhat": "Forecast"}, inplace=True)
forecast = forecast[['Date', 'Forecast']]

# Save the forecast
forecast.to_csv("prophet_forecast.csv", index=False)

# Check output
print(forecast.head())

# Rename columns to match Streamlit expectations
forecast.rename(columns={"ds": "Date", "yhat": "Forecast"}, inplace=True)

# Select only the necessary columns
forecast = forecast[['Date', 'Forecast']]

# Save as CSV
forecast.to_csv("prophet_forecast.csv", index=False)

# Check output format
print(forecast.head())

from google.colab import files
files.download("prophet_forecast.csv")